\chapter{Разработка моделей для оценки задержек}
\label{ch:modeling}

\hspace*{1.25cm}После всестороннего анализа данных на предыдущем этапе, текущая глава посвящена практической разработке и реализации моделей для оценки задержки в видеоаналитическом конвейере. Основное внимание уделяется двум ключевым этапам: инжинирингу признаков, направленному на извлечение максимального количества полезной информации из временных рядов, и выбору, описанию и реализации моделей машинного обучения.

\section{Инжиниринг признаков}
\label{sec:feature_engineering}

\hspace*{1.25cm}Инжиниринг признаков --- это процесс преобразования исходных временных рядов в структурированный набор данных (таблицу), пригодный для обучения моделей машинного обучения. Качество и информативность признаков напрямую влияют на точность и обобщающую способность итоговой модели [6]. На основе анализа, проведенного в Главе 2, был сформирован следующий набор признаков.

\subsection{Календарные и временные признаки}

\hspace*{1.25cm}Эти признаки позволяют модели учитывать зависимости, связанные со временем суток, днем недели и общим течением времени. Они особенно полезны для моделей на основе деревьев решений, таких как CatBoost.

\begin{itemize}
	\item \textbf{Час дня (\texttt{hour})} и \textbf{день недели (\texttt{day\_of\_week})}: категориальные признаки, позволяющие модели улавливать суточные и недельные паттерны.
	\item \textbf{Признак выходного дня (\texttt{is\_weekend})}: бинарный флаг, принимающий значение 1, если день является субботой или воскресеньем, и 0 в противном случае.
	\item \textbf{Временной индекс (\texttt{time\_idx})}: монотонно возрастающая переменная, представляющая собой количество времени (в часах), прошедшее с начала обучающего периода. Этот признак помогает модели аппроксимировать долгосрочный тренд в данных.
\end{itemize}

\subsection{Циклические признаки}

\hspace*{1.25cm}Календарные признаки, такие как час дня или день недели, по своей природе цикличны (после 23:00 идет 00:00). Чтобы донести эту информацию до моделей, особенно нейронных сетей, используются тригонометрические преобразования.

\begin{equation}
	x_{sin} = \sin\left(\frac{2\pi x}{P}\right), \quad x_{cos} = \cos\left(\frac{2\pi x}{P}\right)
\end{equation}
где $x$ — исходное значение (например, час), а $P$ — период цикла (24 для часов, 7 для дней недели). Такой подход преобразует одну переменную в две, представляя ее на единичной окружности.

\subsection{Лаговые признаки (Lag features)}

\hspace*{1.25cm}Лаговые признаки — это значения временного ряда из прошлого, используемые в качестве предикторов для будущих значений. Они являются ключевым способом информирования модели об авторегрессионной структуре данных, выявленной при анализе ACF/PACF. Признак создается путем сдвига временного ряда на $k$ шагов назад:
\begin{equation}
	\text{lag}_k(t) = y(t-k)
\end{equation}
где $y(t-k)$ — значение целевой переменной в момент времени $t-k$.

\hspace*{1.25cm}В данном исследовании для CatBoost-модели использовались лаги: 1, 2, 4, 96, 192, 5760 шагов назад, что соответствует интервалам от 15 секунд до 24 часов. Такой выбор позволяет модели учитывать как непосредственную зависимость от предыдущих значений, так и суточную сезонность (лаг 5760 = 24 часа $\times$ 240 точек/час).

\subsection{Признаки на основе скользящего окна (Rolling-window features)}

\hspace*{1.25cm}Для захвата локальной динамики и структуры временного ряда вычисляются статистические показатели в пределах скользящего окна.

\begin{itemize}
	\item \textbf{Скользящее среднее (\texttt{rolling\_mean})}: сглаживает краткосрочные флуктуации и помогает выявить локальный тренд.
	\item \textbf{Скользящее стандартное отклонение (\texttt{rolling\_std})}: характеризует волатильность (изменчивость) ряда в недавнем прошлом.
\end{itemize}
Размер окна $w$ является гиперпараметром, который выбирается в зависимости от специфики модели и характера данных. В данном исследовании использовались различные наборы параметров для разных типов моделей:

\begin{itemize}
	\item \textbf{Для LSTM-модели}: окна размером 20 и 240 точек данных (соответствующие 5 минутам и 1 часу при 15-секундном интервале);
	\item \textbf{Для CatBoost-модели}: более широкий набор окон --- 4, 96, 192, 1920, 2880, 4320, 5760, 8640 точек данных (от 1 минуты до 36 часов), что позволяет модели улавливать как краткосрочные, так и долгосрочные паттерны.
\end{itemize}

\section{Выбор и описание моделей}
\label{sec:model_selection}

\hspace*{1.25cm}На основе выводов, сделанных в Главе 2, для решения задачи прогнозирования были выбраны модели, представляющие два разных подхода: классическую статистику и современное машинное обучение.

\subsection{Модель SARIMA}
\hspace*{1.25cm}Сезонная авторегрессионная интегрированная скользящая средняя (SARIMA) — это статистическая модель, которая является расширением модели ARIMA и предназначена для работы с временными рядами, обладающими ярко выраженной сезонностью. Выбор этой модели обоснован анализа ACF/PACF, который указал на наличие тренда, авторегрессионной зависимости и сезонных колебаний.

\subsection{Модель CatBoost}
\hspace*{1.25cm}CatBoost — это высокопроизводительная реализация градиентного бустинга над деревьями решений. Она хорошо зарекомендовала себя в работе с разнородными табличными данными, эффективно обрабатывает категориальные признаки и не требует тщательной настройки гиперпараметров.

\subsection{Модель LSTM}
\hspace*{1.25cm}Сети с долгой краткосрочной памятью (Long Short-Term Memory, LSTM) — это разновидность рекуррентных нейронных сетей (RNN), специально разработанная для улавливания долгосрочных зависимостей в последовательных данных. Архитектура LSTM позволяет эффективно бороться с проблемой исчезающих градиентов, что делает ее мощным инструментом для моделирования временных рядов.

\hspace*{1.25cm}В данной работе используется LSTM-архитектура со следующими характеристиками:
\begin{itemize}
	\item Входной слой принимает последовательности длиной \texttt{window\_size} временных шагов с количеством признаков, определяемым этапом feature engineering;
	\item Один LSTM-слой с 64 нейронами;
	\item Полносвязный скрытый слой с 8 нейронами и функцией активации ReLU;
	\item Выходной слой с одним нейроном и линейной функцией активации для регрессии;
	\item Оптимизатор Adam с learning rate 0.0001, функция потерь --- Mean Squared Error.
\end{itemize}

\section{Метрики оценки качества}
\label{sec:evaluation_metrics}

\hspace*{1.25cm}Для оценки качества моделей прогнозирования используется набор метрик, позволяющих комплексно оценить точность оценки задержек. Выбор метрик обусловлен спецификой временных рядов и требованиями к практическому применению системы.

\subsection{Средняя абсолютная процентная ошибка (MAPE)}

\hspace*{1.25cm}MAPE является основной метрикой для оценки качества, поскольку обеспечивает интерпретируемость результатов в процентах:

\begin{equation}
	\text{MAPE} = \frac{100\%}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right|
\end{equation}

где $y_i$ — истинное значение, $\hat{y}_i$ — прогнозируемое значение, $n$ — количество наблюдений. Согласно техническим требованиям, целевое значение MAPE должно быть менее 10\%.

\subsection{Среднеквадратичная ошибка (RMSE)}

\hspace*{1.25cm}RMSE чувствительна к выбросам и позволяет оценить общую точность модели:

\begin{equation}
	\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
\end{equation}

\subsection{Средняя абсолютная ошибка (MAE)}

\hspace*{1.25cm}MAE менее чувствительна к выбросам и показывает среднее отклонение прогнозов:

\begin{equation}
	\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
\end{equation}

\section{Методология проведения экспериментов}
\label{sec:experiment_methodology}

\hspace*{1.25cm}Корректная оценка качества моделей временных рядов требует специального подхода к разделению данных, учитывающего временную структуру и предотвращающего утечку информации из будущего в прошлое.

\subsection{Кросс-валидация для временных рядов}

\hspace*{1.25cm}Для корректной оценки качества моделей применяется специализированная кросс-валидация временных рядов (TimeSeriesSplit), которая учитывает хронологический порядок данных и предотвращает утечку информации из будущего.

\hspace*{1.25cm}Метод TimeSeriesSplit работает следующим образом:
\begin{itemize}
	\item Данные разбиваются на $k$ фолдов, где каждый последующий фолд включает больше исторических данных для обучения;
	\item Для каждого фолда тестовая выборка всегда находится хронологически после обучающей;
	\item Внутри каждого фолда обучающие данные дополнительно разделяются на train и validation в пропорции, определяемой параметром \texttt{test\_size}.
\end{itemize}

\subsection{Процедура валидации}

\hspace*{1.25cm}Для каждого фолда кросс-валидации выполняется следующая последовательность действий:
\begin{enumerate}
	\item \textbf{Разделение данных}: фолд разбивается на train+validation и test согласно TimeSeriesSplit;
	\item \textbf{Внутреннее разделение}: train+validation дополнительно разделяется на обучающую и валидационную выборки;
	\item \textbf{Масштабирование}: параметры нормализации вычисляются только на обучающей выборке и применяются ко всем частям фолда;
	\item \textbf{Обучение модели}: модель обучается на train с валидацией на validation выборке;
	\item \textbf{Оценка качества}: финальная оценка производится на тестовой части фолда;
	\item \textbf{Сохранение результатов}: метрики каждого фолда сохраняются для последующего усреднения.
\end{enumerate}

\hspace*{1.25cm}Итоговые метрики качества вычисляются как среднее арифметическое соответствующих метрик по всем фолдам, что обеспечивает более надежную и несмещенную оценку производительности модели.

\subsection{Горизонт прогнозирования}

\hspace*{1.25cm}Все модели настраиваются для прогнозирования на 900 временных шагов вперед (3.75 часа), что соответствует практическим требованиям системы мониторинга для своевременного реагирования на потенциальные проблемы в видеоконвейере.

