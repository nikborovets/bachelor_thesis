\section{Выбор и описание моделей}
\label{sec:model_selection}

На основе выводов, сделанных в Главе 2, для решения задачи прогнозирования были выбраны модели, представляющие два разных подхода: классическую статистику и современное машинное обучение.

\subsection{Модель SARIMA}
Сезонная авторегрессионная интегрированная скользящая средняя \\(SARIMA) — это статистическая модель, которая является расширением модели ARIMA и предназначена для работы с временными рядами, обладающими ярко выраженной сезонностью [7]. Выбор этой модели обоснован анализом ACF/PACF, который указал на наличие тренда, авторегрессионной зависимости и сезонных колебаний.

\subsection{Модель CatBoost}
CatBoost — это высокопроизводительная реализация градиентного бустинга над деревьями решений [8]. Она хорошо зарекомендовала себя в работе с разнородными табличными данными, эффективно обрабатывает категориальные признаки и не требует тщательной настройки гиперпараметров.

Особенностью предложенного в данной работе подхода является использование гибридной модели на основе CatBoost. Поскольку модели, основанные на деревьях решений, не способны экстраполировать тренд, была применена стратегия декомпозиции временного ряда. Исходный ряд был разделен на три компоненты: тренд, сезонность и остатки. Каждая из этих компонент прогнозировалась отдельно:
\begin{itemize}
    \item \textbf{Тренд} моделировался с помощью отдельной, более простой линейной модели.
    \item \textbf{Сезонная компонента и остатки} прогнозировались основной моделью CatBoost, которая эффективно работает со сложными нелинейными зависимостями после удаления тренда.
\end{itemize}
Итоговый прогноз получался путем суммирования прогнозов по каждой из компонент. Такой подход позволяет сочетать преимущества обоих типов моделей.

\subsection{Модель LSTM}
Сети с долгой краткосрочной памятью (Long Short-Term Memory, LSTM) — это разновидность рекуррентных нейронных сетей (RNN), специально разработанная для улавливания долгосрочных зависимостей в последовательных данных [9].Также архитектура LSTM позволяет эффективно бороться с проблемой затухающих градиентов.

В данной работе используется LSTM-архитектура со следующими характеристиками:
\begin{itemize}
	\item Входной слой принимает последовательности длиной \texttt{window\_size} временных шагов с количеством признаков, определяемым этапом формирования признаков;
	\item Один LSTM-слой с 64 нейронами;
	\item Полносвязный скрытый слой с 8 нейронами и функцией активации ReLU;
	\item Выходной слой с одним нейроном и линейной функцией активации для регрессии;
	\item Оптимизатор Adam с learning rate 0.0001, функция потерь --- Mean Squared Error.
\end{itemize}

\subsection{Дополнительные эксперименты с современными моделями}

В рамках исследования также проводились эксперименты с современными архитектурами для анализа временных рядов, такими как N-BEATS [20], а также с моделями из библиотек Time-Series-Library [10] и AutoTS [11] для оценки их применимости к данной задаче.

\subsubsection{Модели Time-Series-Library}

Были протестированы следующие модели на основе трансформеров и линейных архитектур:
\begin{itemize}
	\item \textbf{DLinear, PatchTST, iTransformer, Crossformer} --- успешно завершили обучение;
	\item \textbf{NLinear, Autoformer, FEDformer, Informer, TimesNet, Transformer} --- завершились с ошибками или превысили лимит времени выполнения.
\end{itemize}

\subsubsection{Модели AutoTS}

Библиотека AutoTS [11] предоставляет автоматизированный подход к выбору и настройке моделей временных рядов. Были протестированы модели:
\begin{itemize}
	\item \textbf{LastValueNaive} --- простая baseline модель;
	\item \textbf{SeasonalityMotif, SectionalMotif} --- модели на основе выявления паттернов;
	\item \textbf{GLS} --- обобщенный метод наименьших квадратов.
\end{itemize}

\subsubsection{Результаты дополнительных экспериментов}

Несмотря на современность указанных архитектур, результаты оказались неудовлетворительными по сравнению с основными моделями (SARIMA, CatBoost, LSTM). Это может быть обусловлено:
\begin{itemize}
	\item Недостаточной настройкой гиперпараметров для специфики данной задачи;
	\item Неоптимальным формированием признаков для трансформер-архитектур;
	\item Различиями в методологии предобработки данных между библиотеками.
\end{itemize}

В связи с этим для финальной оценки были выбраны три основные модели, показавшие наилучшее соотношение качества и стабильности результатов.